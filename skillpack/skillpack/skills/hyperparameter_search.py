"""hyperparameter-search - Generate Optuna or Ray Tune sweep templates."""

import argparse
from datetime import datetime
from pathlib import Path
from textwrap import dedent
from typing import Any

import yaml

from skillpack.utils.output import get_output_dir, write_text


def handler(args: argparse.Namespace) -> int:
    """CLI handler for hyperparameter-search."""
    result = hyperparameter_search_main(
        experiment_name=args.name,
        framework=args.framework,
        model_type=args.model,
        output_dir=args.output_dir,
    )

    if result.get("success"):
        print(f"✅ Generated sweep config: {result['output_dir']}")
        for f in result.get("files", []):
            print(f"   - {f}")
        return 0
    print(f"❌ Error: {result.get('error')}")
    return 1


def register_parser(subparsers: Any) -> None:
    """Register the hyperparameter-search subcommand."""
    parser = subparsers.add_parser(
        "hyperparameter-search",
        help="Generate Optuna or Ray Tune sweep templates",
    )
    parser.add_argument("--name", required=True, help="Experiment name")
    parser.add_argument(
        "--framework",
        choices=["optuna", "ray", "wandb"],
        default="optuna",
        help="HPO framework",
    )
    parser.add_argument(
        "--model",
        choices=["sklearn", "pytorch", "xgboost"],
        default="sklearn",
        help="Model type",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("./out/hyperparameter_search"),
        help="Output directory",
    )
    parser.set_defaults(handler=handler)


def hyperparameter_search_main(
    experiment_name: str,
    framework: str = "optuna",
    model_type: str = "sklearn",
    output_dir: Path | None = None,
) -> dict[str, Any]:
    """Generate hyperparameter search templates."""
    if output_dir is None:
        output_dir = get_output_dir("hyperparameter_search")
    else:
        output_dir.mkdir(parents=True, exist_ok=True)

    try:
        files = []

        if framework == "optuna":
            code = generate_optuna_sweep(experiment_name, model_type)
            write_text(content=code, filename="optuna_sweep.py", skill_name="hyperparameter_search")
            files.append("optuna_sweep.py")
        elif framework == "ray":
            code = generate_ray_tune_sweep(experiment_name, model_type)
            write_text(content=code, filename="ray_tune_sweep.py", skill_name="hyperparameter_search")
            files.append("ray_tune_sweep.py")
        else:  # wandb
            code = generate_wandb_sweep(experiment_name, model_type)
            write_text(content=code, filename="wandb_sweep.py", skill_name="hyperparameter_search")
            config = generate_wandb_config(experiment_name, model_type)
            write_text(content=config, filename="sweep_config.yaml", skill_name="hyperparameter_search")
            files.extend(["wandb_sweep.py", "sweep_config.yaml"])

        # Generate search space config
        search_space = generate_search_space(model_type)
        write_text(content=search_space, filename="search_space.yaml", skill_name="hyperparameter_search")
        files.append("search_space.yaml")

        # Generate README
        readme = generate_readme(experiment_name, framework)
        write_text(content=readme, filename="README.md", skill_name="hyperparameter_search")
        files.append("README.md")

        return {
            "success": True,
            "output_dir": str(output_dir),
            "files": files,
        }

    except Exception as e:
        return {"success": False, "error": str(e)}


def generate_optuna_sweep(name: str, model_type: str) -> str:
    """Generate Optuna sweep script."""
    return dedent(f'''\
        #!/usr/bin/env python3
        """Optuna hyperparameter sweep for {name}.

        Generated by skillpack on {datetime.now().strftime("%Y-%m-%d %H:%M")}
        """

        import optuna
        from optuna.integration import MLflowCallback
        import logging

        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger(__name__)


        def objective(trial: optuna.Trial) -> float:
            """Objective function for optimization."""
            
            # Define hyperparameters
            params = {{
                "learning_rate": trial.suggest_float("learning_rate", 1e-5, 1e-1, log=True),
                "n_estimators": trial.suggest_int("n_estimators", 50, 500),
                "max_depth": trial.suggest_int("max_depth", 3, 15),
                "min_samples_split": trial.suggest_int("min_samples_split", 2, 20),
                "min_samples_leaf": trial.suggest_int("min_samples_leaf", 1, 10),
            }}
            
            # TODO: Load your data
            # X_train, X_val, y_train, y_val = load_data()
            
            # TODO: Create and train model
            # model = create_model(**params)
            # model.fit(X_train, y_train)
            
            # TODO: Calculate validation metric
            # score = model.score(X_val, y_val)
            score = 0.85  # Placeholder
            
            return score


        def main():
            # Create study
            study = optuna.create_study(
                study_name="{name}",
                direction="maximize",
                storage="sqlite:///{name}_optuna.db",
                load_if_exists=True,
            )
            
            # Add callbacks
            callbacks = [
                # MLflowCallback(metric_name="accuracy"),
            ]
            
            # Run optimization
            study.optimize(
                objective,
                n_trials=100,
                timeout=3600,
                callbacks=callbacks,
                show_progress_bar=True,
            )
            
            # Print results
            logger.info(f"Best trial: {{study.best_trial.number}}")
            logger.info(f"Best value: {{study.best_value:.4f}}")
            logger.info(f"Best params: {{study.best_params}}")
            
            # Save best params
            import yaml
            with open("best_params.yaml", "w") as f:
                yaml.dump(study.best_params, f)


        if __name__ == "__main__":
            main()
    ''')


def generate_ray_tune_sweep(name: str, model_type: str) -> str:
    """Generate Ray Tune sweep script."""
    return dedent(f'''\
        #!/usr/bin/env python3
        """Ray Tune hyperparameter sweep for {name}.

        Generated by skillpack on {datetime.now().strftime("%Y-%m-%d %H:%M")}
        """

        from ray import tune
        from ray.tune.schedulers import ASHAScheduler
        from ray.tune.search.optuna import OptunaSearch
        import logging

        logging.basicConfig(level=logging.INFO)


        def train_fn(config: dict) -> None:
            """Training function for Ray Tune."""
            
            # TODO: Load your data
            # X_train, X_val, y_train, y_val = load_data()
            
            # TODO: Create model with config
            # model = create_model(**config)
            
            # Training loop
            for epoch in range(config.get("epochs", 10)):
                # TODO: Train one epoch
                # train_loss = train_epoch(model, X_train, y_train)
                
                # TODO: Validate
                # val_loss, val_acc = validate(model, X_val, y_val)
                val_acc = 0.85 + epoch * 0.01  # Placeholder
                
                # Report metrics to Ray
                tune.report(accuracy=val_acc, epoch=epoch)


        def main():
            # Define search space
            search_space = {{
                "learning_rate": tune.loguniform(1e-5, 1e-1),
                "batch_size": tune.choice([16, 32, 64, 128]),
                "hidden_size": tune.choice([64, 128, 256, 512]),
                "dropout": tune.uniform(0.1, 0.5),
                "epochs": 10,
            }}
            
            # Scheduler for early stopping
            scheduler = ASHAScheduler(
                max_t=10,
                grace_period=2,
                reduction_factor=2,
            )
            
            # Search algorithm
            search_alg = OptunaSearch()
            
            # Run tuning
            analysis = tune.run(
                train_fn,
                config=search_space,
                num_samples=50,
                scheduler=scheduler,
                search_alg=search_alg,
                metric="accuracy",
                mode="max",
                resources_per_trial={{"cpu": 2, "gpu": 0}},
                local_dir="./ray_results",
                name="{name}",
            )
            
            # Print best config
            print(f"Best config: {{analysis.best_config}}")
            print(f"Best accuracy: {{analysis.best_result['accuracy']:.4f}}")


        if __name__ == "__main__":
            main()
    ''')


def generate_wandb_sweep(name: str, model_type: str) -> str:
    """Generate W&B sweep agent script."""
    return dedent(f'''\
        #!/usr/bin/env python3
        """W&B sweep agent for {name}.

        Generated by skillpack on {datetime.now().strftime("%Y-%m-%d %H:%M")}
        """

        import wandb


        def train():
            """Training function called by sweep agent."""
            # Initialize W&B run
            run = wandb.init()
            config = wandb.config
            
            # TODO: Load your data
            # X_train, X_val, y_train, y_val = load_data()
            
            # TODO: Create model with config
            # model = create_model(
            #     learning_rate=config.learning_rate,
            #     hidden_size=config.hidden_size,
            # )
            
            # Training loop
            for epoch in range(config.epochs):
                # TODO: Train and validate
                train_loss = 0.5 - epoch * 0.05  # Placeholder
                val_acc = 0.8 + epoch * 0.02
                
                wandb.log({{
                    "train_loss": train_loss,
                    "val_accuracy": val_acc,
                    "epoch": epoch,
                }})
            
            run.finish()


        def main():
            # Initialize sweep
            sweep_id = wandb.sweep(
                sweep="sweep_config.yaml",
                project="{name}",
            )
            
            # Run agent
            wandb.agent(sweep_id, function=train, count=50)


        if __name__ == "__main__":
            main()
    ''')


def generate_wandb_config(name: str, model_type: str) -> str:
    """Generate W&B sweep config."""
    return yaml.dump({
        "program": "wandb_sweep.py",
        "method": "bayes",
        "metric": {"name": "val_accuracy", "goal": "maximize"},
        "parameters": {
            "learning_rate": {"min": 0.00001, "max": 0.1, "distribution": "log_uniform_values"},
            "hidden_size": {"values": [64, 128, 256, 512]},
            "dropout": {"min": 0.1, "max": 0.5},
            "epochs": {"value": 10},
        },
    }, default_flow_style=False)


def generate_search_space(model_type: str) -> str:
    """Generate search space YAML."""
    if model_type == "sklearn":
        space = {
            "n_estimators": {"type": "int", "low": 50, "high": 500},
            "max_depth": {"type": "int", "low": 3, "high": 15},
            "learning_rate": {"type": "float", "low": 0.001, "high": 0.3, "log": True},
            "min_samples_split": {"type": "int", "low": 2, "high": 20},
        }
    elif model_type == "pytorch":
        space = {
            "learning_rate": {"type": "float", "low": 1e-5, "high": 1e-1, "log": True},
            "batch_size": {"type": "categorical", "values": [16, 32, 64, 128]},
            "hidden_size": {"type": "categorical", "values": [64, 128, 256, 512]},
            "dropout": {"type": "float", "low": 0.1, "high": 0.5},
            "num_layers": {"type": "int", "low": 1, "high": 4},
        }
    else:  # xgboost
        space = {
            "eta": {"type": "float", "low": 0.01, "high": 0.3, "log": True},
            "max_depth": {"type": "int", "low": 3, "high": 12},
            "subsample": {"type": "float", "low": 0.5, "high": 1.0},
            "colsample_bytree": {"type": "float", "low": 0.5, "high": 1.0},
            "min_child_weight": {"type": "int", "low": 1, "high": 10},
        }
    
    return yaml.dump({"search_space": space}, default_flow_style=False)


def generate_readme(name: str, framework: str) -> str:
    """Generate README."""
    return dedent(f'''\
        # Hyperparameter Search: {name}

        Generated by skillpack on {datetime.now().strftime("%Y-%m-%d %H:%M")}

        ## Framework: {framework.title()}

        ## Usage

        ```bash
        # Install dependencies
        pip install {framework} {"mlflow" if framework == "optuna" else ""}

        # Run sweep
        python {framework}_sweep.py
        ```

        ## Files
        - `{framework}_sweep.py` - Main sweep script
        - `search_space.yaml` - Hyperparameter definitions
        - `README.md` - This file

        ## Tips
        - Start with a wide search space, then narrow
        - Use early stopping to save compute
        - Log all metrics for analysis
    ''')
