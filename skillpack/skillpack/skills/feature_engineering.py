"""feature-engineering - Suggest and generate feature transformations per column type."""

import argparse
from datetime import datetime
from pathlib import Path
from textwrap import dedent
from typing import Any

import yaml

from skillpack.utils.output import get_output_dir, write_text


def handler(args: argparse.Namespace) -> int:
    """CLI handler for feature-engineering."""
    # Load config if provided
    config = {}
    if args.config and args.config.exists():
        with open(args.config) as f:
            config = yaml.safe_load(f) or {}

    result = feature_engineering_main(
        columns=config.get("columns", []),
        output_dir=args.output_dir,
    )

    if result.get("success"):
        print(f"✅ Generated feature engineering code in {result['output_dir']}")
        for f in result.get("files", []):
            print(f"   - {f}")
        return 0
    print(f"❌ Error: {result.get('error')}")
    return 1


def register_parser(subparsers: Any) -> None:
    """Register the feature-engineering subcommand."""
    parser = subparsers.add_parser(
        "feature-engineering",
        help="Suggest and generate feature transformations per column type",
    )
    parser.add_argument(
        "--config",
        type=Path,
        help="Path to column configuration YAML",
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("./out/feature_engineering"),
        help="Output directory",
    )
    parser.set_defaults(handler=handler)


def feature_engineering_main(
    columns: list[dict] | None = None,
    output_dir: Path | None = None,
) -> dict[str, Any]:
    """Generate feature engineering code based on column types."""
    if output_dir is None:
        output_dir = get_output_dir("feature_engineering")
    else:
        output_dir.mkdir(parents=True, exist_ok=True)

    # Default example columns if none provided
    if not columns:
        columns = [
            {"name": "age", "type": "numeric"},
            {"name": "created_at", "type": "datetime"},
            {"name": "description", "type": "text"},
            {"name": "category", "type": "categorical"},
            {"name": "latitude", "type": "geo"},
            {"name": "longitude", "type": "geo"},
        ]

    try:
        files = []

        # Generate features.py
        features_code = generate_features_module(columns)
        write_text(content=features_code, filename="features.py", skill_name="feature_engineering")
        files.append("features.py")

        # Generate transformations reference
        transformations = generate_transformations_doc(columns)
        write_text(content=transformations, filename="transformations.md", skill_name="feature_engineering")
        files.append("transformations.md")

        # Generate config template
        config = generate_config_template(columns)
        write_text(content=config, filename="feature_config.yaml", skill_name="feature_engineering")
        files.append("feature_config.yaml")

        return {
            "success": True,
            "output_dir": str(output_dir),
            "files": files,
            "column_count": len(columns),
        }

    except Exception as e:
        return {"success": False, "error": str(e)}


def generate_features_module(columns: list[dict]) -> str:
    """Generate Python feature engineering module."""
    
    # Group columns by type
    numeric_cols = [c["name"] for c in columns if c.get("type") == "numeric"]
    datetime_cols = [c["name"] for c in columns if c.get("type") == "datetime"]
    text_cols = [c["name"] for c in columns if c.get("type") == "text"]
    categorical_cols = [c["name"] for c in columns if c.get("type") == "categorical"]
    geo_cols = [c["name"] for c in columns if c.get("type") == "geo"]

    return dedent(f'''\
        #!/usr/bin/env python3
        """Feature engineering module.
        
        Generated by skillpack feature-engineering on {datetime.now().strftime("%Y-%m-%d %H:%M")}
        """

        import numpy as np
        import pandas as pd
        from sklearn.base import BaseEstimator, TransformerMixin
        from sklearn.compose import ColumnTransformer
        from sklearn.pipeline import Pipeline
        from sklearn.preprocessing import (
            StandardScaler,
            MinMaxScaler,
            OneHotEncoder,
            LabelEncoder,
        )

        # Column definitions
        NUMERIC_COLUMNS = {numeric_cols}
        DATETIME_COLUMNS = {datetime_cols}
        TEXT_COLUMNS = {text_cols}
        CATEGORICAL_COLUMNS = {categorical_cols}
        GEO_COLUMNS = {geo_cols}


        class NumericTransformer(BaseEstimator, TransformerMixin):
            \"\"\"Transform numeric columns with scaling and binning.\"\"\"
            
            def __init__(self, scaling: str = "standard", bins: int | None = None):
                self.scaling = scaling
                self.bins = bins
                self.scaler = None
            
            def fit(self, X: pd.DataFrame, y=None):
                if self.scaling == "standard":
                    self.scaler = StandardScaler()
                elif self.scaling == "minmax":
                    self.scaler = MinMaxScaler()
                
                if self.scaler:
                    self.scaler.fit(X)
                return self
            
            def transform(self, X: pd.DataFrame) -> pd.DataFrame:
                result = X.copy()
                
                # Apply scaling
                if self.scaler:
                    scaled = self.scaler.transform(X)
                    result = pd.DataFrame(scaled, columns=X.columns, index=X.index)
                
                # Add derived features
                for col in X.columns:
                    result[f"{{col}}_log"] = np.log1p(np.abs(X[col]))
                    result[f"{{col}}_squared"] = X[col] ** 2
                    
                    if self.bins:
                        result[f"{{col}}_binned"] = pd.qcut(
                            X[col], q=self.bins, labels=False, duplicates="drop"
                        )
                
                return result


        class DatetimeTransformer(BaseEstimator, TransformerMixin):
            \"\"\"Extract features from datetime columns.\"\"\"
            
            def fit(self, X: pd.DataFrame, y=None):
                return self
            
            def transform(self, X: pd.DataFrame) -> pd.DataFrame:
                result = pd.DataFrame(index=X.index)
                
                for col in X.columns:
                    dt = pd.to_datetime(X[col])
                    
                    # Time components
                    result[f"{{col}}_year"] = dt.dt.year
                    result[f"{{col}}_month"] = dt.dt.month
                    result[f"{{col}}_day"] = dt.dt.day
                    result[f"{{col}}_dayofweek"] = dt.dt.dayofweek
                    result[f"{{col}}_hour"] = dt.dt.hour
                    
                    # Cyclical encoding
                    result[f"{{col}}_month_sin"] = np.sin(2 * np.pi * dt.dt.month / 12)
                    result[f"{{col}}_month_cos"] = np.cos(2 * np.pi * dt.dt.month / 12)
                    result[f"{{col}}_dow_sin"] = np.sin(2 * np.pi * dt.dt.dayofweek / 7)
                    result[f"{{col}}_dow_cos"] = np.cos(2 * np.pi * dt.dt.dayofweek / 7)
                    
                    # Is weekend
                    result[f"{{col}}_is_weekend"] = dt.dt.dayofweek >= 5
                
                return result


        class TextTransformer(BaseEstimator, TransformerMixin):
            \"\"\"Extract basic features from text columns.\"\"\"
            
            def fit(self, X: pd.DataFrame, y=None):
                return self
            
            def transform(self, X: pd.DataFrame) -> pd.DataFrame:
                result = pd.DataFrame(index=X.index)
                
                for col in X.columns:
                    text = X[col].fillna("")
                    
                    # Basic stats
                    result[f"{{col}}_length"] = text.str.len()
                    result[f"{{col}}_word_count"] = text.str.split().str.len()
                    result[f"{{col}}_char_count"] = text.str.replace(" ", "").str.len()
                    
                    # Ratios
                    result[f"{{col}}_upper_ratio"] = (
                        text.str.count(r"[A-Z]") / text.str.len().replace(0, 1)
                    )
                    result[f"{{col}}_digit_ratio"] = (
                        text.str.count(r"\\d") / text.str.len().replace(0, 1)
                    )
                    
                    # Contains patterns
                    result[f"{{col}}_has_url"] = text.str.contains(r"https?://").astype(int)
                    result[f"{{col}}_has_email"] = text.str.contains(r"@").astype(int)
                
                return result


        class CategoricalTransformer(BaseEstimator, TransformerMixin):
            \"\"\"Encode categorical columns.\"\"\"
            
            def __init__(self, encoding: str = "onehot", max_categories: int = 10):
                self.encoding = encoding
                self.max_categories = max_categories
                self.encoders = {{}}
            
            def fit(self, X: pd.DataFrame, y=None):
                for col in X.columns:
                    # Get top categories
                    top_cats = X[col].value_counts().head(self.max_categories).index.tolist()
                    self.encoders[col] = top_cats
                return self
            
            def transform(self, X: pd.DataFrame) -> pd.DataFrame:
                result = pd.DataFrame(index=X.index)
                
                for col in X.columns:
                    top_cats = self.encoders.get(col, [])
                    
                    # Create "other" category
                    mapped = X[col].apply(lambda x: x if x in top_cats else "other")
                    
                    if self.encoding == "onehot":
                        dummies = pd.get_dummies(mapped, prefix=col)
                        result = pd.concat([result, dummies], axis=1)
                    else:
                        result[col] = mapped.astype("category").cat.codes
                
                return result


        class GeoTransformer(BaseEstimator, TransformerMixin):
            \"\"\"Create features from geographic coordinates.\"\"\"
            
            def __init__(self, center_lat: float = 0, center_lon: float = 0):
                self.center_lat = center_lat
                self.center_lon = center_lon
            
            def fit(self, X: pd.DataFrame, y=None):
                return self
            
            def transform(self, X: pd.DataFrame) -> pd.DataFrame:
                result = X.copy()
                
                # Assumes pairs of lat/lon columns
                lat_cols = [c for c in X.columns if "lat" in c.lower()]
                lon_cols = [c for c in X.columns if "lon" in c.lower()]
                
                for lat_col, lon_col in zip(lat_cols, lon_cols):
                    prefix = lat_col.replace("lat", "").replace("_", "")
                    
                    # Distance from center
                    result[f"{{prefix}}_dist_from_center"] = np.sqrt(
                        (X[lat_col] - self.center_lat) ** 2 + 
                        (X[lon_col] - self.center_lon) ** 2
                    )
                    
                    # Geohash-like binning
                    result[f"{{prefix}}_lat_bin"] = (X[lat_col] * 10).round()
                    result[f"{{prefix}}_lon_bin"] = (X[lon_col] * 10).round()
                
                return result


        def create_feature_pipeline() -> ColumnTransformer:
            \"\"\"Create complete feature engineering pipeline.\"\"\"
            return ColumnTransformer([
                ("numeric", NumericTransformer(scaling="standard"), NUMERIC_COLUMNS),
                ("datetime", DatetimeTransformer(), DATETIME_COLUMNS),
                ("text", TextTransformer(), TEXT_COLUMNS),
                ("categorical", CategoricalTransformer(), CATEGORICAL_COLUMNS),
                ("geo", GeoTransformer(), GEO_COLUMNS),
            ], remainder="drop")


        if __name__ == "__main__":
            # Example usage
            import pandas as pd
            
            # Create sample data
            df = pd.DataFrame({{
                "age": [25, 30, 35],
                "created_at": ["2024-01-15", "2024-02-20", "2024-03-25"],
                "description": ["Hello world", "Test text here", "Another example"],
                "category": ["A", "B", "A"],
                "latitude": [40.7, 34.0, 41.8],
                "longitude": [-74.0, -118.2, -87.6],
            }})
            
            pipeline = create_feature_pipeline()
            features = pipeline.fit_transform(df)
            print(f"Original shape: {{df.shape}}")
            print(f"Transformed shape: {{features.shape}}")
    ''')


def generate_transformations_doc(columns: list[dict]) -> str:
    """Generate transformations documentation."""
    
    type_transforms = {
        "numeric": [
            "StandardScaler / MinMaxScaler",
            "Log transform (log1p)",
            "Squared values",
            "Quantile binning",
        ],
        "datetime": [
            "Year, month, day extraction",
            "Day of week, hour",
            "Cyclical encoding (sin/cos)",
            "Is weekend flag",
        ],
        "text": [
            "Length, word count",
            "Character ratios (upper, digit)",
            "Pattern detection (URL, email)",
        ],
        "categorical": [
            "One-hot encoding",
            "Label encoding",
            "Frequency encoding",
        ],
        "geo": [
            "Distance from center",
            "Lat/lon binning",
            "Haversine distance",
        ],
    }
    
    column_section = "\n".join([
        f"| {c['name']} | {c['type']} | {', '.join(type_transforms.get(c['type'], ['N/A'])[:2])} |"
        for c in columns
    ])
    
    return dedent(f'''\
        # Feature Engineering Transformations

        Generated by skillpack feature-engineering on {datetime.now().strftime("%Y-%m-%d %H:%M")}

        ## Column Summary

        | Column | Type | Suggested Transforms |
        |--------|------|---------------------|
{column_section}

        ## Transformation Details

        ### Numeric Features
        - **Scaling**: StandardScaler (z-score) or MinMaxScaler (0-1)
        - **Log Transform**: `log1p(x)` to handle skewed distributions
        - **Polynomial**: Squared values for non-linear relationships
        - **Binning**: Quantile-based discretization

        ### Datetime Features
        - **Components**: year, month, day, hour, minute
        - **Cyclical**: sin/cos encoding for periodic patterns
        - **Boolean**: is_weekend, is_holiday, is_business_hours

        ### Text Features
        - **Basic**: length, word_count, character_count
        - **Ratios**: uppercase_ratio, digit_ratio, special_char_ratio
        - **Patterns**: contains_url, contains_email, contains_phone
        - **Advanced**: TF-IDF, word embeddings (separate step)

        ### Categorical Features
        - **One-Hot**: Best for low cardinality (<10 categories)
        - **Label**: Ordinal encoding for tree-based models
        - **Target**: Mean/count encoding (requires target variable)

        ### Geographic Features
        - **Distance**: Haversine distance from reference point
        - **Clustering**: Lat/lon grid binning
        - **Derived**: City, region lookup via reverse geocoding
    ''')


def generate_config_template(columns: list[dict]) -> str:
    """Generate configuration YAML template."""
    return yaml.dump(
        {
            "columns": columns,
            "transformers": {
                "numeric": {"scaling": "standard", "bins": 10},
                "datetime": {"cyclical": True, "components": ["year", "month", "dayofweek"]},
                "text": {"features": ["length", "word_count", "patterns"]},
                "categorical": {"encoding": "onehot", "max_categories": 10},
                "geo": {"center_lat": 0.0, "center_lon": 0.0},
            },
        },
        default_flow_style=False,
    )
